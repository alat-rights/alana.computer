---
layout: page
#title: Alana
permalink: /
---

**Hi! I'm Alana.**

My goal is to make the future awesome. I currently do AI safety research. I'm on a leave of absence from Stanford University.

In the past, I have:
- Built systems to catch bad actors for [WhatsApp](https://faq.whatsapp.com/1805617343145907)
- Conducted [pre-release safety testing on GPT-4](https://metr.org/blog/2023-08-01-new-report/) for ARC Evals (now [METR](https://metr.org/blog/2023-12-04-metr-announcement/))
- Studied worst-case risks from AI at the [Center on Long-Term Risk](https://longtermrisk.org/)
- Conducted research on the AI alignment problem with Vivek Hebbar via the [MATS program](https://www.matsprogram.org/)

These days, I think about:
- How to test, monitor, secure, and contain powerful future AI systems
- How to build infrastructure and tooling that speed up researchers
- The inner lives of transformers

You might want to...
- Check out [alana-utils](https://utils.alana.computer/), my opionated Python library for LLM-heavy workflows.
- Check out [eval-awareness](https://github.com/alat-rights/evalawareness), my ongoing research into LLMs' ability to discriminate between evaluation and deployment environments.
- Keep up with my every move on [GitHub](https://github.com/alat-rights).
- Say hi! (My email address is hi @ my-second-level-domain (dot) my-top-level-domain). I'd love to hear about what you've been working on and/or thinking about.
